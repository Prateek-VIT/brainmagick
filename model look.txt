Init shape: torch.Size([16, 208, 343])
Merger shape: torch.Size([16, 270, 343])
Initial Linear shape: torch.Size([16, 270, 343])
Subject shape: torch.Size([16, 270, 343])


{
    'concatenate': False, 
    'depth': 10, 
    'linear_out': False, 
    'complex_out': True,
    'kernel_size': 3,
    'dilation_growth': 2,
    'dilation_period': 5,
    'skip': True, 
    'post_skip': False,
    'growth': 1.0,
    'scale': None, 
    'rewrite': False,
    'groups': 1,
    'glu': 2,
    'glu_context': 1,
    'glu_glu': True,
    'gelu': True,
    'dual_path': 0,
    'conv_dropout': 0.0,
    'dropout_input': 0.0,
    'batch_norm': True,
    'relu_leakiness': 0.0,
    'subject_dim': 0,
    'subject_layers': True,
    'embedding_scale': 1.0,
    'subject_layers_dim': 'input',
    'subject_layers_id': False,
    'n_fft': None,
    'fft_complex': True, 
    'merger': True,
    'merger_pos_dim': 2048,
    'merger_channels': 270,
    'merger_dropout': 0.2,
    'merger_penalty': 0.0,
    'merger_per_subject': False,
    'dropout': 0.0,
    'dropout_rescale': True,
    'initial_linear': 270,
    'initial_depth': 1,
    'initial_nonlin': False,
    'hidden': {'meg': 320}
}

